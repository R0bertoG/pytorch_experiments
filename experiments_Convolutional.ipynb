{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conv2d expect a 4D tensor. In order to make a 2D convolution we need a 2D Tensor, obviously. But you can make a 2D convolution over different channels (for instance color channels in an image), so a 3D tensor is required (in the case of grayscale images, the size of this additional image is 1). And the convolutional operation is build so it can process batches, so it needs an extra dimenssion. So 4D for 2D images.\n",
    "\n",
    "In order to make a 3D convolution you need a 5D Tensor. A 3D convolution is and operaton in a 3D space, so you need a 3D tensor, for the aditional needed dimensions (from 3D until 5D) it's the same reason that for a 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t4 = torch.Tensor([[[[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]]]])\n",
    "t5 = torch.Tensor([[[\n",
    "    [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]]\n",
    "    , [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]]\n",
    "    , [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]]\n",
    "    , [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]]\n",
    "]]])\n",
    "t4.size()\n",
    "t4 = torch.autograd.Variable(t4)\n",
    "t5 = torch.autograd.Variable(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters: input_channels, output_channels, kernel_size\n",
    "conv_2d = torch.nn.Conv2d(1, 16, 1)\n",
    "conv_3d = torch.nn.Conv3d(1, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n",
      "torch.Size([1, 16, 4, 4])\n",
      "torch.Size([1, 16, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "#TODO: investigate: ct2d = torch.nn.ConvTranspose2d(c2d, 1 ,1)\n",
    "\n",
    "c2d = conv_2d(t4)\n",
    "print(t4.size())\n",
    "print(c2d.size())\n",
    "c3d = conv_3d(t5)\n",
    "print(c3d.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike pooling, convolution is not changing the size except in the dimension of the 'output filters'.\n",
    "The operation of convolution can reduce the number of 'filters' also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "conv_2d_16 = torch.nn.Conv2d(16, 8, 1)\n",
    "c2d2 = conv_2d_16(c2d)\n",
    "print(c2d2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vector:\n",
      " Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "[torch.FloatTensor of size 1x1x4x4]\n",
      "\n",
      "pooling with kernel size 1:\n",
      " Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "[torch.FloatTensor of size 1x1x4x4]\n",
      "\n",
      "pooling with kernel size 2:\n",
      " Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1  1\n",
      "  1  1  1\n",
      "  1  1  1\n",
      "[torch.FloatTensor of size 1x1x3x3]\n",
      "\n",
      "pooling with kernel size 3:\n",
      " Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "[torch.FloatTensor of size 1x1x2x2]\n",
      "\n",
      "pooling with kernel size 4:\n",
      " Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1\n",
      "[torch.FloatTensor of size 1x1x1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"original vector:\\n\", t4)\n",
    "for kernel_size in range(1, 5):\n",
    "    pol2d = torch.nn.MaxPool2d(kernel_size, stride=1)\n",
    "    pc2d = pol2d(t4)\n",
    "    print(\"pooling with kernel size \" + str(kernel_size) + \":\\n\" , pc2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "[torch.FloatTensor of size 1x1x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pol2d = torch.nn.MaxPool2d(2, stride=1)\n",
    "pc2d = pol2d(pol2d(t4))\n",
    "print(pc2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1  1\n",
      "  1  1  1\n",
      "  1  1  1\n",
      "[torch.FloatTensor of size 1x1x3x3]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1\n",
      "[torch.FloatTensor of size 1x1x1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Explore torch.nn.MaxUnpool2d(\n",
    "pol2d = torch.nn.MaxPool2d(2, stride=1)\n",
    "pc2d = pol2d(t4)\n",
    "ups = torch.nn.Upsample(size=(1,1), scale_factor=None, mode='bilinear')\n",
    "upsampled_pc2d_bilinear = ups(pc2d)\n",
    "'''\n",
    "ups = torch.nn.Upsample(size=1, scale_factor=None, mode='nearest')\n",
    "upsampled_pc2d_nearest = ups(pc2d)\n",
    "'''\n",
    "print(pc2d)\n",
    "print(upsampled_pc2d_bilinear)\n",
    "#print(upsampled_pc2d_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "  1  1  1  1\n",
      "[torch.FloatTensor of size 1x1x4x4]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  1  1  1\n",
      "  1  1  1\n",
      "  1  1  1\n",
      "[torch.FloatTensor of size 1x1x3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaPool2d = torch.nn.AdaptiveMaxPool2d((3,3))\n",
    "adat4 = adaPool2d(t4)\n",
    "print(t4)\n",
    "print(adat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
